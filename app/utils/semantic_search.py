from typing import List, Optional
import faiss
import numpy as np
from loguru import logger
from app.utils.catalog import Car, CarCatalog
from app.config import Settings
from app.llm.gigachat_client import gigachat_embeddings


class SemanticCarIndex:
    """
    Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÐµÐ¹ Ð¿Ð¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ð¼ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸ÑÐ¼.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ GigaChat API Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð¸ Faiss Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°.
    """
    
    def __init__(self, catalog: CarCatalog, settings: Settings):
        logger.info("ðŸ”„ Initializing SemanticCarIndex with GigaChat API...")
        self.catalog = catalog
        self.settings = settings
        self.cars: List[Car] = []
        self.index: Optional[faiss.Index] = None
        
        # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ñ€Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        self._build_index()
    
    async def _get_embeddings(self, texts: List[str]) -> np.ndarray:
        if not texts:
            logger.error("âŒ Empty texts list for embeddings")
            raise ValueError("Cannot get embeddings for empty texts list")
        
        batch_size = 10
        all_embeddings = []
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            logger.info(f"ðŸ“¦ Processing batch {batch_num}/{total_batches} ({len(batch)} texts)...")
            
            try:
                embeddings = await gigachat_embeddings(batch, self.settings)
                
                if not embeddings:
                    logger.error(f"âŒ Empty embeddings received for batch {batch_num}")
                    raise ValueError(f"Empty embeddings for batch {batch_num}")
                
                all_embeddings.extend(embeddings)
                logger.info(f"âœ… Batch {batch_num}/{total_batches} processed: {len(embeddings)} embeddings")
                
            except Exception as e:
                logger.error(f"âŒ Error getting embeddings for batch {batch_num}: {e}")
                try:
                    logger.info("ðŸ”„ Retrying batch...")
                    embeddings = await gigachat_embeddings(batch, self.settings)
                    if not embeddings: raise ValueError("Retry failed")
                    all_embeddings.extend(embeddings)
                    logger.info(f"âœ… Batch {batch_num}/{total_batches} processed after retry")
                except Exception as retry_error:
                    raise RuntimeError(f"Failed to get embeddings for batch {batch_num}: {retry_error}") from retry_error
        
        return np.array(all_embeddings, dtype=np.float32)
    
    def _build_index(self):
        import asyncio
        import nest_asyncio
        try: nest_asyncio.apply()
        except: pass
        
        self.cars = self.catalog.get_all_cars()
        logger.info(f"ðŸ“‹ Found {len(self.cars)} cars in catalog")
        
        if not self.cars:
            logger.error("âŒ No cars in catalog - cannot build semantic index!")
            self.index = None
            raise RuntimeError("Catalog is empty - cannot build semantic index")
        
        descriptions = []
        for car in self.cars:
            desc = self._car_to_description(car)
            descriptions.append(desc)
        
        logger.info(f"ðŸ“¥ Getting embeddings for {len(descriptions)} cars via GigaChat API...")
        
        try:
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, self._get_embeddings(descriptions))
                        embeddings = future.result(timeout=600)
                else:
                    embeddings = loop.run_until_complete(self._get_embeddings(descriptions))
            except RuntimeError:
                embeddings = asyncio.run(self._get_embeddings(descriptions))
            
            if embeddings.shape[0] != len(self.cars):
                raise RuntimeError(f"Embeddings count mismatch")
            
            dimension = embeddings.shape[1]
            logger.info(f"ðŸ”¨ Building Faiss index with dimension={dimension}...")
            self.index = faiss.IndexFlatL2(dimension)
            faiss.normalize_L2(embeddings)
            self.index.add(embeddings.astype('float32'))
            logger.info(f"âœ…âœ…âœ… Built Faiss index with {self.index.ntotal} vectors")
        except Exception as e:
            logger.exception(f"âŒ Error building index: {e}")
            self.index = None
            raise RuntimeError(f"Failed to build semantic index: {e}") from e
    
    def _car_to_description(self, car: Car) -> str:
        """ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÑŒ Ð² Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð»Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°."""
        drive_text = {
            "4x4": "Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð²Ð¾Ð´",
            "awd": "Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð²Ð¾Ð´",
            "fwd": "Ð¿ÐµÑ€ÐµÐ´Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸Ð²Ð¾Ð´",
            "rwd": "Ð·Ð°Ð´Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸Ð²Ð¾Ð´",
        }.get(car.drive.lower(), car.drive)
        
        return (
            f"{car.brand} {car.model} {car.trim}, {car.body}, {drive_text}, "
            f"{car.engine_type}, {car.power} Ð».Ñ., {car.transmission} {car.gears} ÑÑ‚, "
            f"Ñ†ÐµÐ½Ð° {car.final_price} Ñ€ÑƒÐ±"
        )
    
    async def search(
        self,
        query: str,
        dealer_brands: set[str],
        body: Optional[str] = None,
        drive: Optional[str] = None,
        price_max: Optional[int] = None,
        power_min: Optional[int] = None,
        transmission: Optional[str] = None,
        gears: Optional[int] = None,
        engine_type: Optional[str] = None,
        price_min: Optional[int] = None,
        top_k: int = 10,
    ) -> List[Car]:
        if self.index is None or not self.cars:
            logger.warning("Semantic search not available, falling back to structural search")
            return self.catalog.search(
                dealer_brands, body, drive, price_max, 
                power_min, transmission, gears, engine_type, price_min
            )
        
        logger.info(f"ðŸ” Semantic search: query='{query[:100]}', top_k={top_k}")
        
        query_embeddings = await self._get_embeddings([query])
        query_embedding = query_embeddings[0].astype('float32').reshape(1, -1)
        faiss.normalize_L2(query_embedding)
        
        k = min(top_k, self.index.ntotal)
        distances, indices = self.index.search(query_embedding, k)
        
        candidates = [self.cars[idx] for idx in indices[0]]
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ðº ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð°Ð¼
        filtered = []
        for car in candidates:
            if car.brand not in dealer_brands: continue
            if body and body != "Ð»ÑŽÐ±Ð¾Ð¹" and car.body.lower() != body.lower(): continue
            if drive:
                # Normalize drive (simplified)
                d_req = drive.lower()
                d_car = car.drive.lower()
                is_awd_req = any(x in d_req for x in ["4x4", "awd", "Ð¿Ð¾Ð»Ð½"])
                is_awd_car = any(x in d_car for x in ["4x4", "awd", "Ð¿Ð¾Ð»Ð½"])
                if is_awd_req != is_awd_car: continue # Rough check
                
            if price_max and car.final_price > price_max: continue
            if price_min and car.final_price < price_min: continue
            
            if power_min and car.power < (power_min * 0.9): continue
            
            # Transmission/Engine strict filtering is NOT applied here intentionally 
            # because semantic search is for "fuzzy" intents. 
            # If strict filtering is needed, non_dealer_choice switches to catalog.search.
            
            filtered.append(car)
        
        logger.info(f"Semantic search found {len(filtered)} cars after filtering")
        return filtered
